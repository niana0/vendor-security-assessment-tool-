"""
Vendor Security Assessment Tool - Streamlit UI
"""
import streamlit as st
import os
from pathlib import Path
import tempfile
import shutil
from datetime import datetime

# Import our modules
from src.document_parser import DocumentParser
from src.evidence_extractor import EvidenceExtractor
from src.questionnaire_mapper import QuestionnaireMapper
from src.risk_assessor import RiskAssessor
from src.web_search_agent import WebSearchAgent
from src.vendor_overview_extractor import VendorOverviewExtractor
from src.atlassian_mcp_integration import AtlassianMCPIntegration


# Page config
st.set_page_config(
    page_title="Vendor Security Assessment Tool",
    page_icon="üîí",
    layout="wide"
)

# Initialize session state
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'results' not in st.session_state:
    st.session_state.results = {}
if 'vendor_metadata' not in st.session_state:
    st.session_state.vendor_metadata = {}


def save_uploaded_file(uploaded_file, directory):
    """Save uploaded file to directory"""
    file_path = os.path.join(directory, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path


def _create_web_search_placeholder(vendor_metadata: dict, output_path: str):
    """Create placeholder report for web search only mode"""
    vendor_name = vendor_metadata.get('vendor_name', 'Unknown Vendor')

    content = f"""# Vendor Risk Assessment Report
# {vendor_name}

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Assessment Mode:** Public Information Analysis (No documents provided)

---

## ‚ö†Ô∏è Action Required: Web Search Needed

This assessment requires publicly available information about **{vendor_name}**.

**To complete this assessment, ask Claude:**

> "Please perform web searches for {vendor_name} and generate a comprehensive risk assessment report including certifications, security incidents, and security practices."

---

## Vendor Context

**Vendor Name:** {vendor_name}
**Services:** {vendor_metadata.get('services', 'Not specified')}
**Integration Points:** {vendor_metadata.get('integrations', 'Not specified')}
**Data Handled:** {vendor_metadata.get('data_stored', 'Not specified')}

---

## What Will Be Searched

Claude will perform web searches to gather:

1. **Company Information**
   - Company overview and services
   - Market position and reputation
   - Business model and customer base

2. **Security Posture**
   - Published security practices
   - Security controls and architecture
   - Encryption and access control measures

3. **Certifications & Compliance**
   - SOC 2, ISO 27001, FedRAMP status
   - Industry-specific certifications
   - Compliance frameworks

4. **Security Incidents**
   - Historical breaches or vulnerabilities
   - Incident response and remediation
   - Timeline and impact assessment

5. **Third-Party Reviews**
   - Security ratings and assessments
   - Customer feedback on security
   - Independent audits

---

## Next Steps

1. **Request Claude to perform web search** (see command above)
2. **Review generated comprehensive report** with findings
3. **Optionally provide documents** for deeper analysis
4. **Make vendor decision** based on combined information

---

*Generated by Vendor Security Assessment Tool*
"""

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)


def perform_web_search_api(vendor_name: str) -> dict:
    """
    Perform web searches for vendor security information using WebSearchAgent

    Args:
        vendor_name: Name of the vendor to search for

    Returns:
        Dictionary with search results (controls, incidents)
    """
    try:
        agent = WebSearchAgent()
        results = agent.search_vendor_security(vendor_name)
        return results

    except Exception as e:
        # Gracefully handle search failures
        print(f"Web search failed: {e}")
        return {'controls': [], 'incidents': []}


def process_documents(vendor_files, questionnaire_file, vendor_metadata, progress_bar, status_text):
    """Main processing pipeline - handles both document and web search assessment"""
    results = {}
    results['vendor_metadata'] = vendor_metadata
    has_documents = bool(vendor_files and questionnaire_file)

    try:
        # Create temp directory for processing
        temp_dir = tempfile.mkdtemp()
        output_dir = "output"
        os.makedirs(output_dir, exist_ok=True)

        # Step 0: Integrate Jira/Rovo data if available
        if st.session_state.get('jira_data'):
            status_text.text("üìä Integrating Jira/Rovo data...")
            progress_bar.progress(5)

            jira_integration = AtlassianMCPIntegration()
            vendor_metadata = jira_integration.update_vendor_metadata(
                vendor_metadata,
                st.session_state.jira_data
            )
            results['vendor_metadata'] = vendor_metadata
            results['jira_data'] = st.session_state.jira_data

        evidence = []

        # Step 1: Process documents if provided
        if has_documents:
            # Save uploaded files
            status_text.text("üìÅ Saving uploaded files...")
            progress_bar.progress(10)

            vendor_paths = []
            for vf in vendor_files:
                path = save_uploaded_file(vf, temp_dir)
                vendor_paths.append(path)

            questionnaire_path = save_uploaded_file(questionnaire_file, temp_dir)

            # Parse documents
            status_text.text("üìÑ Parsing vendor documents...")
            progress_bar.progress(20)

            parser = DocumentParser()
            parsed_docs = parser.parse_all(vendor_paths)
            results['parsed_count'] = len(parsed_docs)

            # Extract evidence from documents
            status_text.text("üîç Extracting security evidence from documents...")
            progress_bar.progress(35)

            extractor = EvidenceExtractor()
            evidence = extractor.extract_all(parsed_docs)
            results['document_evidence_count'] = len(evidence)
        else:
            results['parsed_count'] = 0
            results['document_evidence_count'] = 0
            questionnaire_path = None

        # Step 2: Perform live web search for public information
        status_text.text("üåê Searching public security information...")
        progress_bar.progress(50)

        vendor_name = vendor_metadata.get('vendor_name', '')
        web_results = {'controls': [], 'incidents': []}
        search_error = None

        if vendor_name:
            try:
                status_text.text(f"üîç Searching web for {vendor_name} security information...")
                web_results = perform_web_search_api(vendor_name)

                # Convert web search results to evidence format
                web_agent = WebSearchAgent()
                web_agent.search_results = web_results
                web_evidence = web_agent.to_evidence_format()

                # Merge web evidence with document evidence
                evidence.extend(web_evidence)

                results['web_incidents_count'] = len(web_results.get('incidents', []))
                results['web_controls_count'] = len(web_results.get('controls', []))
                results['web_evidence_count'] = len(web_evidence)

                # Debug info
                if results['web_controls_count'] == 0 and results['web_incidents_count'] == 0:
                    search_error = "Web search completed but found no results. This may indicate a search provider issue."

            except Exception as e:
                search_error = f"Web search error: {str(e)}"
                st.warning(f"‚ö†Ô∏è Web search encountered an issue: {str(e)}")
                results['web_incidents_count'] = 0
                results['web_controls_count'] = 0
                results['web_evidence_count'] = 0
        else:
            results['web_incidents_count'] = 0
            results['web_controls_count'] = 0
            results['web_evidence_count'] = 0

        results['web_search_results'] = web_results
        results['web_search_error'] = search_error
        results['needs_web_search'] = False
        results['vendor_name'] = vendor_name

        # Step 2.5: Extract vendor overview information
        status_text.text("üìä Extracting vendor overview...")
        progress_bar.progress(60)

        overview_extractor = VendorOverviewExtractor()
        vendor_overview = overview_extractor.extract_overview(
            vendor_name=vendor_name,
            parsed_docs=parsed_docs if has_documents else None,
            web_results=web_results,
            evidence=evidence,
            vendor_metadata=vendor_metadata
        )
        results['vendor_overview'] = vendor_overview

        # Step 3: Load questionnaire and map evidence (if questionnaire provided)
        if questionnaire_path:
            status_text.text("üìã Mapping evidence to questionnaire...")
            progress_bar.progress(65)

            mapper = QuestionnaireMapper()
            questions = mapper.load_questionnaire(questionnaire_path)

            if not questions:
                st.error("Could not find questions in the questionnaire file. Please check the format.")
                return None

            mappings = mapper.map_evidence_to_questions(questions, evidence)
            results['questions_count'] = len(mappings)
            results['has_questionnaire'] = True
        else:
            # No questionnaire - generate basic assessment
            mappings = []
            results['questions_count'] = 0
            results['has_questionnaire'] = False

        # Step 4: Risk assessment
        status_text.text("‚ö†Ô∏è Performing risk assessment...")
        progress_bar.progress(80)

        assessor = RiskAssessor()

        if mappings:
            # Full assessment with questionnaire
            risk_assessment = assessor.assess(
                mappings,
                vendor_metadata=vendor_metadata,
                web_search_results=results.get('web_search_results', {})
            )
        else:
            # Basic assessment without questionnaire - web search based
            web_search_results = results.get('web_search_results', {})
            incidents_count = len(web_search_results.get('incidents', []))
            controls_count = len(web_search_results.get('controls', []))

            # Calculate risk based on web findings (balanced approach)
            risk_level = 'MEDIUM RISK'
            risk_score = 50
            risks = []
            recommendations = []

            # Assess based on controls first (positive signal)
            if controls_count >= 8:
                # Excellent security posture
                risk_level = 'LOW RISK'
                risk_score = 25
            elif controls_count >= 5:
                # Good security posture
                risk_level = 'LOW RISK'
                risk_score = 35
            elif controls_count >= 3:
                # Moderate security posture
                risk_level = 'MEDIUM RISK'
                risk_score = 50
            elif controls_count > 0:
                # Limited security information
                risk_level = 'MEDIUM RISK'
                risk_score = 60
            else:
                # No security information found
                risk_level = 'HIGH RISK'
                risk_score = 75

            # Assess incidents (negative signal) - adjust risk upward if needed
            if incidents_count >= 5:
                risk_level = 'HIGH RISK'
                risk_score = max(risk_score, 80)
                risks.append({
                    'severity': 'HIGH',
                    'category': 'Security History',
                    'description': f'{incidents_count} security incidents found in public records',
                    'gaps': [f'Review details of all {incidents_count} incidents']
                })
                recommendations.append({
                    'priority': 'Critical',
                    'category': 'Security History',
                    'action': 'Investigate security incidents history',
                    'rationale': f'Multiple security incidents ({incidents_count}) found in public sources',
                    'questions_to_followup': ['What remediation was performed?', 'Were customers notified?']
                })
            elif incidents_count >= 2:
                # Multiple incidents - increase risk but don't override if good controls
                if risk_level == 'LOW RISK' and controls_count >= 5:
                    risk_level = 'MEDIUM RISK'
                    risk_score = 45
                else:
                    risk_score = min(70, risk_score + 15)
                risks.append({
                    'severity': 'MEDIUM',
                    'category': 'Security History',
                    'description': f'{incidents_count} security incidents found in public records',
                    'gaps': ['Review incident details and remediation']
                })
                recommendations.append({
                    'priority': 'High',
                    'category': 'Security History',
                    'action': 'Review security incident details',
                    'rationale': f'Found {incidents_count} security incidents in public sources',
                    'questions_to_followup': ['What was the root cause?', 'What controls were added?']
                })
            elif incidents_count == 1:
                # Single incident - minor concern if old or if good controls exist
                if controls_count < 3:
                    risk_score = min(65, risk_score + 10)
                risks.append({
                    'severity': 'LOW',
                    'category': 'Security History',
                    'description': '1 security incident found in public records',
                    'gaps': ['Review incident details and remediation']
                })

            # Add recommendation if limited controls
            if controls_count < 3:
                risks.append({
                    'severity': 'MEDIUM' if controls_count == 0 else 'LOW',
                    'category': 'Security Controls',
                    'description': f'Limited public security information found ({controls_count} controls)',
                    'gaps': ['Request security documentation', 'Verify certifications']
                })
                recommendations.append({
                    'priority': 'High' if controls_count == 0 else 'Medium',
                    'category': 'Due Diligence',
                    'action': 'Request comprehensive security documentation',
                    'rationale': 'Limited public security information available',
                    'questions_to_followup': ['Do you have SOC 2?', 'What certifications do you hold?']
                })

            # No information found at all
            if controls_count == 0 and incidents_count == 0:
                risk_level = 'HIGH RISK'
                risk_score = 70
                risks.append({
                    'severity': 'HIGH',
                    'category': 'Lack of Information',
                    'description': 'No public security information found',
                    'gaps': ['Unable to verify security posture', 'No certifications found']
                })
                recommendations.append({
                    'priority': 'Critical',
                    'category': 'Due Diligence',
                    'action': 'Perform comprehensive vendor security assessment',
                    'rationale': 'No public security information available for this vendor',
                    'questions_to_followup': ['Provide security questionnaire', 'Share SOC 2 or equivalent reports']
                })

            risk_assessment = {
                'overall_risk': risk_level,
                'risk_score': risk_score,
                'confidence_distribution': {
                    'WEB_SEARCH': controls_count + incidents_count
                },
                'risks': risks,
                'threat_model': {},
                'recommendations': recommendations,
                'public_incidents_found': incidents_count,
                'summary': {
                    'total_questions': 0,
                    'answered_high_confidence': 0,
                    'answered_medium_confidence': 0,
                    'answered_low_confidence': 0,
                    'insufficient_evidence': 0,
                    'critical_risks': len([r for r in risks if r['severity'] == 'HIGH']),
                    'medium_risks': len([r for r in risks if r['severity'] == 'MEDIUM']),
                    'low_risks': len([r for r in risks if r['severity'] == 'LOW'])
                }
            }

        # Step 5: Generate outputs
        status_text.text("üìä Generating reports...")
        progress_bar.progress(90)

        # Save outputs
        output_dir = "output"
        vendor_safe_name = vendor_metadata.get('vendor_name', 'vendor').replace(' ', '_')

        if has_documents:
            excel_path = os.path.join(output_dir, f"{vendor_safe_name}_questionnaire.xlsx")
            risk_md_path = os.path.join(output_dir, f"{vendor_safe_name}_assessment.md")

            if questionnaire_path:
                mapper.to_excel(excel_path)
            assessor.to_markdown(risk_md_path)

            results['excel_path'] = excel_path if questionnaire_path else None
            results['risk_md_path'] = risk_md_path
        else:
            # Web search only - create placeholder report
            risk_md_path = os.path.join(output_dir, f"{vendor_safe_name}_web_assessment.md")
            _create_web_search_placeholder(vendor_metadata, risk_md_path)
            results['excel_path'] = None
            results['risk_md_path'] = risk_md_path

        results['mappings'] = mappings
        results['risk_assessment'] = risk_assessment
        results['assessment_mode'] = 'hybrid' if has_documents else 'web_search_only'

        # Cleanup temp directory
        shutil.rmtree(temp_dir)

        progress_bar.progress(100)
        status_text.text("‚úÖ Processing complete!")

        return results

    except Exception as e:
        st.error(f"Error during processing: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return None


def display_results(results):
    """Display processing results in UI"""

    assessment_mode = results.get('assessment_mode', 'hybrid')
    vendor_name = results.get('vendor_name', results.get('vendor_metadata', {}).get('vendor_name', 'the vendor'))

    # Show mode banner and web search results
    if assessment_mode == 'web_search_only':
        st.info("üåê **Assessment Mode:** Public Information Only - No documents provided")
    elif assessment_mode == 'hybrid':
        st.success("üìä **Assessment Mode:** Hybrid Analysis (Documents + Public Information)")

    # Vendor Overview - DISPLAY AT TOP
    if results.get('vendor_overview') or results.get('vendor_metadata'):
        st.header("üìã Vendor Overview")

        # Use extracted overview if available, otherwise fall back to metadata
        overview = results.get('vendor_overview', {})
        metadata = results.get('vendor_metadata', {})

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Vendor Information")
            vendor_name_display = overview.get('vendor_name') or metadata.get('vendor_name', 'N/A')
            st.write(f"**Name:** {vendor_name_display}")

            # Display description if available
            if overview.get('description'):
                description = overview['description']
                # Only add ellipsis if actually truncating
                if len(description) > 500:
                    st.write(f"**Description:** {description[:500]}...")
                else:
                    st.write(f"**Description:** {description}")

            # Display services
            services = overview.get('services', [])
            if services:
                st.write("**Services Provided:**")
                for service in services[:6]:
                    st.write(f"- {service}")
            elif metadata.get('services'):
                services_text = metadata['services']
                if len(services_text) > 300:
                    st.write(f"**Services:** {services_text[:300]}...")
                else:
                    st.write(f"**Services:** {services_text}")

        with col2:
            st.subheader("Data & Integration Scope")

            # Display data processed
            data_processed = overview.get('data_processed', [])
            if data_processed:
                st.write("**Data Processed:**")
                for data_type in data_processed[:6]:
                    st.write(f"- {data_type}")
            elif metadata.get('data_stored'):
                data_text = metadata['data_stored']
                if len(data_text) > 300:
                    st.write(f"**Data Stored:** {data_text[:300]}...")
                else:
                    st.write(f"**Data Stored:** {data_text}")

            # Display integrations
            integrations = overview.get('integrations', [])
            if integrations:
                st.write("**Integrations:**")
                for integration in integrations[:6]:
                    st.write(f"- {integration}")
            elif metadata.get('integrations'):
                integrations_text = metadata['integrations']
                if len(integrations_text) > 300:
                    st.write(f"**Integrations:** {integrations_text[:300]}...")
                else:
                    st.write(f"**Integrations:** {integrations_text}")

        st.markdown("---")

    # Display web search statistics
    st.markdown("### üåê Web Search Results")

    # Show search error if any
    if results.get('web_search_error'):
        st.error(f"‚ö†Ô∏è {results['web_search_error']}")
        st.info("üí° **Troubleshooting tips:**\n- Check your internet connection\n- Try again (DuckDuckGo may be rate-limiting)\n- Install search library: `pip install duckduckgo-search`")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("Security Controls Found", results.get('web_controls_count', 0))
    with col2:
        st.metric("Security Incidents Found", results.get('web_incidents_count', 0))
    with col3:
        st.metric("Total Web Evidence", results.get('web_evidence_count', 0))

    if results.get('web_evidence_count', 0) > 0 or results.get('web_incidents_count', 0) > 0:

        # Show some web search details
        if results.get('web_search_results'):
            web_results = results['web_search_results']

            if web_results.get('incidents'):
                with st.expander(f"üö® View {len(web_results['incidents'])} Security Incidents"):
                    for incident in web_results['incidents'][:5]:
                        st.markdown(f"**{incident.get('title', 'Unknown')}** ({incident.get('year', 'Unknown year')})")
                        st.caption(incident.get('snippet', '')[:200] + '...')
                        st.caption(f"Source: {incident.get('url', '')}")
                        st.markdown("---")

            if web_results.get('controls'):
                with st.expander(f"‚úÖ View {len(web_results['controls'])} Security Controls"):
                    for control in web_results['controls'][:5]:
                        st.markdown(f"**{control.get('title', 'Unknown')}**")
                        st.caption(control.get('snippet', '')[:200] + '...')
                        st.caption(f"Confidence: {control.get('confidence', 'UNKNOWN')} | Source: {control.get('url', '')}")
                        st.markdown("---")

        st.markdown("---")

    # Overall Risk Assessment
    st.header("üéØ Risk Assessment Summary")

    risk = results['risk_assessment']

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric("Overall Risk", risk['overall_risk'])
    with col2:
        st.metric("Risk Score", f"{risk['risk_score']}/100")
    with col3:
        st.metric("Critical Risks", risk['summary']['critical_risks'])
    with col4:
        st.metric("Questions Assessed", risk['summary']['total_questions'])
    with col5:
        st.metric("Public Incidents", risk.get('public_incidents_found', 0))

    # Confidence Distribution
    st.subheader("üìä Confidence Distribution")
    conf_dist = risk['confidence_distribution']

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("High Confidence", conf_dist.get('HIGH', 0),
                 delta_color="normal")
    with col2:
        st.metric("Medium Confidence", conf_dist.get('MEDIUM', 0))
    with col3:
        st.metric("Low Confidence", conf_dist.get('LOW', 0))
    with col4:
        st.metric("No Evidence", conf_dist.get('NOT_FOUND', 0),
                 delta_color="inverse")

    # Threat Modeling Section
    if risk.get('threat_model'):
        st.subheader("üéØ Threat Modeling (STRIDE Framework)")

        threat_model = risk['threat_model']

        # Attack Surfaces
        attack_surfaces = threat_model.get('attack_surfaces', [])
        if attack_surfaces:
            st.write("**Attack Surfaces:**")
            for surface in attack_surfaces:
                exposure_emoji = {'HIGH': 'üî¥', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}.get(surface['exposure_level'], '‚ö™')
                with st.expander(f"{exposure_emoji} {surface['surface']} - {surface['exposure_level']} Exposure"):
                    st.write(surface['description'])

        # STRIDE Threats
        threats = threat_model.get('threats', [])
        if threats:
            st.write("**STRIDE Threat Analysis:**")

            # Group by category
            threat_categories = {}
            for threat in threats:
                cat = threat['category']
                if cat not in threat_categories:
                    threat_categories[cat] = []
                threat_categories[cat].append(threat)

            for category, cat_threats in threat_categories.items():
                with st.expander(f"üîç {category} ({len(cat_threats)} threat(s))"):
                    for threat in cat_threats:
                        severity_emoji = {'HIGH': 'üî¥', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}.get(threat['severity'], '‚ö™')
                        st.write(f"{severity_emoji} **{threat['severity']}:** {threat['description']}")
                        st.caption(f"Impact: {threat['potential_impact']}")

        st.markdown("---")

    # Key Risks
    st.subheader("‚ö†Ô∏è Key Risks Identified")

    if risk['risks']:
        for r in risk['risks']:
            severity_color = {
                'HIGH': 'üî¥',
                'MEDIUM': 'üü°',
                'LOW': 'üü¢'
            }.get(r['severity'], '‚ö™')

            with st.expander(f"{severity_color} {r['severity']} - {r['category']}"):
                st.write(f"**Description:** {r['description']}")
                if r.get('gaps'):
                    st.write("**Evidence Gaps:**")
                    for gap in r['gaps'][:3]:
                        st.write(f"- {gap}")
    else:
        st.success("No significant risks identified!")

    # Recommendations
    st.subheader("üí° Recommendations")

    if risk['recommendations']:
        for idx, rec in enumerate(risk['recommendations'], 1):
            priority_emoji = {
                'Critical': 'üî¥',
                'High': 'üü†',
                'Medium': 'üü°',
                'Low': 'üü¢'
            }.get(rec['priority'], '‚ö™')

            with st.expander(f"{priority_emoji} [{rec['priority']}] {rec['action']}"):
                st.write(f"**Category:** {rec['category']}")
                st.write(f"**Rationale:** {rec['rationale']}")
                if rec.get('questions_to_followup'):
                    st.write(f"**Follow-up Questions:** {', '.join(rec['questions_to_followup'][:5])}")
    else:
        st.info("No specific recommendations at this time.")

    # Question Details
    st.subheader("üìã Questionnaire Details")

    # Filter options
    filter_conf = st.multiselect(
        "Filter by Confidence Level",
        ['HIGH', 'MEDIUM', 'LOW', 'NOT_FOUND'],
        default=['NOT_FOUND', 'LOW']
    )

    filtered_mappings = [m for m in results['mappings']
                         if m['confidence'] in filter_conf]

    st.write(f"Showing {len(filtered_mappings)} questions")

    for mapping in filtered_mappings[:20]:  # Show first 20
        with st.expander(f"{mapping['question_id']}: {mapping['question'][:100]}..."):
            st.write(f"**Answer:** {mapping['answer']}")
            st.write(f"**Confidence:** {mapping['confidence']}")

            if mapping['evidence']:
                st.write("**Evidence:**")
                for ev in mapping['evidence'][:2]:
                    st.write(f"- {ev['source']}")
                    st.caption(f"  {ev['evidence_text'][:200]}...")

            if mapping['gaps']:
                st.write("**Gaps:**")
                for gap in mapping['gaps']:
                    st.write(f"- {gap}")

    # Download links
    st.subheader("üì• Download Reports")

    col1, col2 = st.columns(2)

    with col1:
        if results.get('excel_path') and os.path.exists(results['excel_path']):
            with open(results['excel_path'], 'rb') as f:
                st.download_button(
                    "üìä Download Completed Questionnaire (Excel)",
                    f,
                    file_name="completed_questionnaire.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        elif not results.get('has_questionnaire'):
            st.info("üí° Upload a questionnaire to get Excel output")

    with col2:
        if results.get('risk_md_path') and os.path.exists(results['risk_md_path']):
            with open(results['risk_md_path'], 'r') as f:
                st.download_button(
                    "üìÑ Download Risk Assessment Report (Markdown)",
                    f,
                    file_name="risk_assessment_report.md",
                    mime="text/markdown"
                )


# Main UI
def main():
    st.title("üîí Vendor Security Assessment Tool")
    st.markdown("---")

    # Sidebar
    with st.sidebar:
        st.header("About")
        st.info("""
        This tool automates vendor security assessments by:

        1. Parsing vendor documentation (PDF, Excel)
        2. Extracting security evidence
        3. Searching public information (live web search)
        4. Combining all evidence sources
        5. Generating comprehensive risk reports
        """)

        st.markdown("---")

        st.header("üìñ How It Works")
        with st.expander("‚ö° Quick Overview"):
            st.markdown("""
            **One-Click Assessment:**

            Click "Generate Risk Assessment"
            - Processes documents (if provided)
            - Performs live web searches automatically
            - Extracts security evidence
            - Generates comprehensive report

            **Total time:** 1-2 minutes

            **Web Search Providers:**
            - Default: DuckDuckGo (free)
            - Optional: Google Custom Search
            - Optional: Bing Search API
            """)

        st.markdown("---")
        st.caption("Built with Streamlit & Claude Code")

    # File upload section
    if not st.session_state.processed:
        # Vendor Information Form
        st.header("üìù Vendor Information")
        st.markdown("Provide context about the vendor being assessed.")

        col1, col2 = st.columns(2)

        with col1:
            vendor_name = st.text_input(
                "Vendor Name *",
                placeholder="e.g., CloudSecure Inc.",
                help="Full legal name of the vendor",
                key="vendor_name_input"
            )

            # Jira/Rovo Integration
            use_jira = st.checkbox(
                "üîó Fetch data from Jira/Rovo Agent",
                help="Pull vendor information from Jira tickets and Rovo agent",
                key="use_jira_checkbox"
            )

            if use_jira and vendor_name:
                with st.spinner(f"Fetching data from Jira for {vendor_name}..."):
                    try:
                        jira_integration = AtlassianMCPIntegration()
                        jira_data = jira_integration.get_vendor_overview_from_jira(vendor_name)

                        if jira_data:
                            st.success(f"‚úÖ Found {jira_data.get('jira_tickets_found', 0)} Jira tickets")

                            # Show summary of Jira data
                            if jira_data.get('security_issues'):
                                st.warning(f"‚ö†Ô∏è {len(jira_data['security_issues'])} security issues found in Jira")
                            if jira_data.get('privacy_concerns'):
                                st.info(f"‚ÑπÔ∏è {len(jira_data['privacy_concerns'])} privacy concerns found")

                            # Store Jira data in session state
                            st.session_state.jira_data = jira_data
                        else:
                            st.info("‚ÑπÔ∏è No Jira tickets found for this vendor")
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Jira integration error: {str(e)}")
                        st.caption("Make sure ATLASSIAN_URL, ATLASSIAN_EMAIL, and ATLASSIAN_API_TOKEN are set in .env")

            in_scope_services = st.text_area(
                "In-scope services provided to Datadog *",
                placeholder="e.g., Cloud infrastructure management, automated backups, monitoring services",
                help="List all services this vendor provides to Datadog",
                height=100,
                key="services_input"
            )

        with col2:
            integration_systems = st.text_area(
                "Applications/systems this vendor integrates with *",
                placeholder="e.g., AWS, Azure, Datadog production environment, CI/CD pipeline",
                help="List systems/applications where this vendor has access or integration",
                height=100,
                key="systems_input"
            )

            data_stored = st.text_area(
                "Data points vendor stores *",
                placeholder="e.g., Customer PII, system logs, API credentials, performance metrics",
                help="Types of data the vendor stores or has access to",
                height=100,
                key="data_input"
            )

        # Store metadata in session state
        st.session_state.vendor_metadata = {
            'vendor_name': vendor_name,
            'services': in_scope_services,
            'integrations': integration_systems,
            'data_stored': data_stored
        }

        metadata_complete = bool(vendor_name)  # Only vendor name required

        st.markdown("---")

        st.header("üì§ Upload Documents")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Vendor Documentation")
            vendor_files = st.file_uploader(
                "Upload vendor documents (PDF, Excel)",
                type=['pdf', 'xlsx', 'xls'],
                accept_multiple_files=True,
                key="vendor_files"
            )

            if vendor_files:
                st.success(f"‚úÖ {len(vendor_files)} file(s) uploaded")
                for vf in vendor_files:
                    st.caption(f"- {vf.name}")

        with col2:
            st.subheader("Questionnaire")
            questionnaire_file = st.file_uploader(
                "Upload Datadog questionnaire (Excel)",
                type=['xlsx', 'xls'],
                key="questionnaire"
            )

            if questionnaire_file:
                st.success(f"‚úÖ {questionnaire_file.name}")

        st.markdown("---")

        # Show assessment mode info
        has_documents = bool(vendor_files and questionnaire_file)

        if metadata_complete:
            # Show clear process explanation
            st.markdown("### üìã **How This Works (2 Simple Steps)**")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                **Step 1: Click Button Below** ‚¨áÔ∏è
                - Process any uploaded documents
                - Prepare for web search
                - Takes ~30 seconds
                """)

            with col2:
                st.markdown("""
                **Step 2: Request Search from Claude** üí¨
                - Copy/paste command shown
                - Claude performs web searches
                - Takes ~2-3 minutes
                """)

            if has_documents:
                st.success("üìä **Mode:** Hybrid - Documents + Public Info (documents prioritized)")
            else:
                st.info("üåê **Mode:** Public Information Analysis")

        # Process button - enabled if vendor name provided
        process_button = st.button(
            "üéØ Generate Risk Assessment (Step 1 of 2)",
            type="primary",
            disabled=not metadata_complete,
            use_container_width=True,
            help="Start assessment - you'll then request web search from Claude in Step 2"
        )

        if not metadata_complete:
            st.warning("‚ö†Ô∏è Please provide the Vendor Name to proceed.")

        if process_button:
            progress_bar = st.progress(0)
            status_text = st.empty()

            # Show processing indicator
            with st.spinner("Processing..."):
                # First, process any documents
                results = process_documents(
                    vendor_files,
                    questionnaire_file,
                    st.session_state.vendor_metadata,
                    progress_bar,
                    status_text
                )

                if results:
                    # Store results and show web search request
                    st.session_state.processed = True
                    st.session_state.results = results
                    st.session_state.awaiting_web_search = True
                    st.rerun()

    else:
        # Display results
        display_results(st.session_state.results)

        st.markdown("---")

        # Reset button
        if st.button("üîÑ Process New Documents"):
            st.session_state.processed = False
            st.session_state.results = {}
            st.session_state.vendor_metadata = {}
            st.rerun()


if __name__ == "__main__":
    main()
